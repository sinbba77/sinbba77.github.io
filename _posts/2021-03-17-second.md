# ë‹¨ì–´ í† í°í™”(Word Tokenization)


```python
import nltk
nltk.download('punkt')
```

    [nltk_data] Downloading package punkt to /root/nltk_data...
    [nltk_data]   Unzipping tokenizers/punkt.zip.
    




    True




```python
from nltk.tokenize import word_tokenize  
print(word_tokenize("Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop."))  
```

    ['Do', "n't", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', "'s", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']
    


```python
from nltk.tokenize import WordPunctTokenizer  
print(WordPunctTokenizer().tokenize("Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop."))
```

    ['Don', "'", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', "'", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']
    


```python
from tensorflow.keras.preprocessing.text import text_to_word_sequence
print(text_to_word_sequence("Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop."))
```

    ["don't", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', "jone's", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']
    


```python
from nltk.tokenize import TreebankWordTokenizer
tokenizer=TreebankWordTokenizer()
text="Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own."
print(tokenizer.tokenize(text))
```

    ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', "n't", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']
    

# ë¬¸ì¥ í† í°í™”(Sentence Tokenization)


```python
from nltk.tokenize import sent_tokenize
text="His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near."
print(sent_tokenize(text))
```

    ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']
    


```python
from nltk.tokenize import sent_tokenize
text="I am actively looking for Ph.D. students. and you are a Ph.D student."
print(sent_tokenize(text))
```

    ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']
    

##í•œêµ­ì–´ ë¬¸ì¥ í† í°í™” ë„êµ¬
ë°•ìƒê¸¸ë‹˜ì´ ê°œë°œí•œ KSS(Korean Sentence Splitter)


```python
pip install kss
```

    Collecting kss
    [?25l  Downloading https://files.pythonhosted.org/packages/c9/e2/43ac92280810437a552111db85a0379dfaa5ca8ccd81d27a547e9091e5d5/kss-2.5.0-py3-none-any.whl (68kB)
    [K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 3.0MB/s 
    [?25hInstalling collected packages: kss
    Successfully installed kss-2.5.0
    


```python
import kss
text='ë”¥ ëŸ¬ë‹ ìì—°ì–´ ì²˜ë¦¬ê°€ ì¬ë¯¸ìˆê¸°ëŠ” í•©ë‹ˆë‹¤. ê·¸ëŸ°ë° ë¬¸ì œëŠ” ì˜ì–´ë³´ë‹¤ í•œêµ­ì–´ë¡œ í•  ë•Œ ë„ˆë¬´ ì–´ë ¤ì›Œìš”. ë†ë‹´ì•„ë‹ˆì—ìš”. ì´ì œ í•´ë³´ë©´ ì•Œê±¸ìš”?'
print(kss.split_sentences(text))
```

    ['ë”¥ ëŸ¬ë‹ ìì—°ì–´ ì²˜ë¦¬ê°€ ì¬ë¯¸ìˆê¸°ëŠ” í•©ë‹ˆë‹¤.', 'ê·¸ëŸ°ë° ë¬¸ì œëŠ” ì˜ì–´ë³´ë‹¤ í•œêµ­ì–´ë¡œ í•  ë•Œ ë„ˆë¬´ ì–´ë ¤ì›Œìš”.', 'ë†ë‹´ì•„ë‹ˆì—ìš”.', 'ì´ì œ í•´ë³´ë©´ ì•Œê±¸ìš”?']
    
